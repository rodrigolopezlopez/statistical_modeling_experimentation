{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "368d4912",
      "metadata": {},
      "source": [
        "# A/B Test (t-test) as a Special Case of Simple Linear Regression\n",
        "\n",
        "## Introduction\n",
        "\n",
        "An **A/B test** compares the means of two groups (e.g., Control vs Treatment) to decide if a treatment has a statistically significant effect. The classic tool is the **two-sample t-test** ($t$-statistic and $p$-value).\n",
        "\n",
        "**Simple linear regression** models the relationship between a predictor and an outcome. When the predictor is **binary** (e.g., group = 0 or 1), we are effectively modeling the mean in each group: the intercept is the control mean, and the slope is the **difference in means** (treatment effect).\n",
        "\n",
        "> **Key Takeaway:** Comparing two group means with a t-test is mathematically equivalent to fitting a regression of outcome on a binary group indicator. This notebook proves that equivalence with synthetic data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f51bd399",
      "metadata": {},
      "source": [
        "---\n",
        "## Synthetic Data Generation\n",
        "\n",
        "We create a dataset with $N = 1000$ samples: 50% Control ($x = 0$) and 50% Treatment ($x = 1$). The true treatment effect is $\\beta_1 = 0.5$; we add Gaussian noise so that $y = \\beta_0 + \\beta_1 x + \\varepsilon$ with $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a10d75",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Parameters\n",
        "N = 1000\n",
        "BETA_0 = 1.0   # Control mean (intercept)\n",
        "BETA_1 = 0.5   # True treatment effect (difference in means)\n",
        "NOISE_STD = 1.0\n",
        "\n",
        "# 50% Control (x=0), 50% Treatment (x=1)\n",
        "group = np.repeat([0, 1], N // 2)\n",
        "# Outcome: y = beta_0 + beta_1 * x + noise\n",
        "y = BETA_0 + BETA_1 * group + np.random.normal(0, NOISE_STD, size=N)\n",
        "\n",
        "df = pd.DataFrame({\"y\": y, \"group\": group})\n",
        "df[\"group_label\"] = df[\"group\"].map({0: \"Control\", 1: \"Treatment\"})\n",
        "\n",
        "# Sanity check: sample means\n",
        "print(\"Sample means by group:\")\n",
        "print(df.groupby(\"group_label\")[\"y\"].agg([\"mean\", \"std\", \"count\"]))\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87981507",
      "metadata": {},
      "source": [
        "---\n",
        "## Method 1: The Classic t-Test\n",
        "\n",
        "We use an independent two-sample t-test with **equal variance** (`equal_var=True`) to test whether the means of the two groups differ. (Equal variance is required for exact equivalence with OLS.) We will compare the resulting **t-statistic** and **p-value** with the regression output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08279867",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_control = df.loc[df[\"group\"] == 0, \"y\"].values\n",
        "y_treatment = df.loc[df[\"group\"] == 1, \"y\"].values\n",
        "\n",
        "# Equal variance (for exact equivalence with OLS); use equal_var=True\n",
        "t_stat_ttest, p_value_ttest = stats.ttest_ind(y_treatment, y_control, equal_var=True)\n",
        "\n",
        "print(\"Method 1 — Two-sample t-test (equal variance)\")\n",
        "print(\"-\" * 45)\n",
        "print(f\"  t-statistic:  {t_stat_ttest:.6f}\")\n",
        "print(f\"  p-value:     {p_value_ttest:.6f}\")\n",
        "print(f\"  Mean (Control):   {y_control.mean():.6f}\")\n",
        "print(f\"  Mean (Treatment): {y_treatment.mean():.6f}\")\n",
        "print(f\"  Difference in means: {y_treatment.mean() - y_control.mean():.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c67776f5",
      "metadata": {},
      "source": [
        "---\n",
        "## Method 2: The Regression Model\n",
        "\n",
        "We fit the model $y = \\beta_0 + \\beta_1 \\cdot \\text{group} + \\varepsilon$ using OLS. Here $\\beta_0$ is the control mean and $\\beta_1$ is the treatment effect (difference in means). The **t-statistic** and **p-value** for the `group` coefficient will match the t-test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94dcdbba",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = ols(\"y ~ group\", data=df).fit()\n",
        "print(\"Method 2 — OLS Regression: y ~ group\")\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c14d3adb",
      "metadata": {},
      "source": [
        "---\n",
        "## The \"Proof\" Comparison\n",
        "\n",
        "We extract the regression t-score and p-value for the `group` coefficient and the estimated $\\beta_1$ (treatment effect). These must match the t-test and the difference in group means to at least 4 decimal places.\n",
        "\n",
        "> **Key Takeaway:** The table below shows that the t-statistic, p-value, and treatment effect from the t-test and from OLS are identical to at least 4 decimal places — the two methods are the same model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24b9aa8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract regression stats for the 'group' coefficient (row index 1)\n",
        "t_stat_ols = model.tvalues[\"group\"]\n",
        "p_value_ols = model.pvalues[\"group\"]\n",
        "beta_1_ols = model.params[\"group\"]\n",
        "\n",
        "diff_means = y_treatment.mean() - y_control.mean()\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    \"Quantity\": [\n",
        "        \"t-statistic\",\n",
        "        \"p-value\",\n",
        "        \"Treatment effect (diff in means / beta_1)\",\n",
        "    ],\n",
        "    \"T-test\": [t_stat_ttest, p_value_ttest, diff_means],\n",
        "    \"Regression (OLS)\": [t_stat_ols, p_value_ols, beta_1_ols],\n",
        "    \"Match (4 decimals)?\": [\n",
        "        np.isclose(t_stat_ttest, t_stat_ols, atol=1e-4),\n",
        "        np.isclose(p_value_ttest, p_value_ols, atol=1e-4),\n",
        "        np.isclose(diff_means, beta_1_ols, atol=1e-4),\n",
        "    ],\n",
        "})\n",
        "comparison[\"T-test\"] = comparison[\"T-test\"].round(6)\n",
        "comparison[\"Regression (OLS)\"] = comparison[\"Regression (OLS)\"].round(6)\n",
        "print(comparison.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Proof: All three quantities match to at least 4 decimal places.\")\n",
        "print(\"=\" * 60)\n",
        "assert np.isclose(t_stat_ttest, t_stat_ols, atol=1e-4), \"t-statistics differ!\"\n",
        "assert np.isclose(p_value_ttest, p_value_ols, atol=1e-4), \"p-values differ!\"\n",
        "assert np.isclose(diff_means, beta_1_ols, atol=1e-4), \"Effect estimates differ!\"\n",
        "print(\"Assertions passed: T-test and OLS are numerically equivalent.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d64a0c8",
      "metadata": {},
      "source": [
        "---\n",
        "## Visualizations\n",
        "\n",
        "**Left:** Distribution of the outcome by group (boxplot and violin). **Right:** Regression line of $y$ on `group` — the line connects the two group means, and its slope equals $\\beta_1$ (the treatment effect)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a9f556f",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Boxplot and violin by group\n",
        "sns.violinplot(data=df, x=\"group_label\", y=\"y\", ax=axes[0], color=\"lightblue\")\n",
        "sns.boxplot(data=df, x=\"group_label\", y=\"y\", ax=axes[0], width=0.3)\n",
        "axes[0].set_title(\"Distribution of y by Group\")\n",
        "axes[0].set_ylabel(\"y\")\n",
        "\n",
        "# Regression line: best-fit line connecting the two group means\n",
        "sns.regplot(data=df, x=\"group\", y=\"y\", ax=axes[1], ci=95, scatter_kws={\"alpha\": 0.4})\n",
        "axes[1].set_title(\"Regression: y ~ group (line connects group means)\")\n",
        "axes[1].set_xlabel(\"group (0 = Control, 1 = Treatment)\")\n",
        "axes[1].set_ylabel(\"y\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8b46465",
      "metadata": {},
      "source": [
        "---\n",
        "## Conclusion\n",
        "\n",
        "> **Key Takeaway:** The two-sample t-test (equal variance) and simple linear regression with a binary group predictor produce **identical** t-statistics, p-values, and effect estimates. They are the same model.\n",
        "\n",
        "**Why this matters:** Framing A/B testing as regression unlocks powerful extensions: you can **add covariates** (e.g., baseline metrics, segment) to control for confounding and reduce variance, use **heteroskedasticity-robust** standard errors, or extend to **multiple treatments** and interactions. Regression generalizes the t-test to \"dirty\" real-world data while keeping the same interpretation for the treatment effect."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
